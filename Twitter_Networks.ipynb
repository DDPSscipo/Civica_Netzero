{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DDPSscipo/Civica_Netzero/blob/main/Twitter_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05751308",
      "metadata": {
        "id": "05751308",
        "outputId": "62032dc2-2dbc-4394-d4e6-ab817674da4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ndjson in /Users/jiexuanchen/opt/anaconda3/lib/python3.8/site-packages (0.3.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install ndjson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8215221",
      "metadata": {
        "id": "c8215221"
      },
      "outputs": [],
      "source": [
        "### Merge (if needed) and convert ndjson data to json-ish format\n",
        "import ndjson\n",
        "import os\n",
        "\n",
        "def merge_ndjson_files(directory):\n",
        "    merged_data = []\n",
        "    seen = set()\n",
        "\n",
        "    # Iterate through all files in the directory\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".ndjson\"):\n",
        "            filepath = os.path.join(directory, filename)\n",
        "            with open(filepath, \"r\") as file:\n",
        "                data = ndjson.load(file)\n",
        "                # Iterate through each item in the data\n",
        "                for item in data:\n",
        "                    # Check that the item is not a duplicate\n",
        "                    tweet_id = item[\"item_id\"]\n",
        "                    if tweet_id not in seen:\n",
        "                        merged_data.append(item)\n",
        "                        seen.add(tweet_id)\n",
        "    return merged_data\n",
        "\n",
        "merged_data = merge_ndjson_files('./Twitter')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0d81ad0",
      "metadata": {
        "id": "a0d81ad0"
      },
      "outputs": [],
      "source": [
        "### Clean twitter data\n",
        "\n",
        "def clean_data(raw_data):\n",
        "    cleaned = []\n",
        "\n",
        "    for item in raw_data:\n",
        "        # Tweet id\n",
        "        tweet_id = item[\"item_id\"]\n",
        "\n",
        "        # The author's metadata\n",
        "        userInfos = item[\"data\"]['core']['user_results']['result']\n",
        "\n",
        "        user_id = userInfos['rest_id']\n",
        "        user_followers_count = userInfos['legacy']['followers_count']\n",
        "        user_location = userInfos['legacy']['location']\n",
        "        user_screen_name = userInfos['legacy']['screen_name'] #user's name shown in url\n",
        "\n",
        "        # Viewed\n",
        "        views_count = item[\"data\"][\"views\"].get(\"count\")\n",
        "        # Favorited\n",
        "        favorite_count = item[\"data\"][\"legacy\"][\"favorite_count\"]\n",
        "        # Retweeted\n",
        "        retweet_count = item[\"data\"][\"legacy\"][\"retweet_count\"]\n",
        "        # Full text\n",
        "        full_text = item[\"data\"][\"legacy\"][\"full_text\"]\n",
        "        # Created at\n",
        "        created_at = item[\"data\"][\"legacy\"][\"created_at\"]\n",
        "        # Hashtags\n",
        "        hashtags = [tag[\"text\"] for tag in item[\"data\"][\"legacy\"][\"entities\"][\"hashtags\"]]\n",
        "\n",
        "        #Conversation Id\n",
        "        conversation_id = item[\"data\"][\"legacy\"][\"conversation_id_str\"]\n",
        "\n",
        "        #Quoted tweet\n",
        "        quoted_info = item[\"data\"].get(\"quoted_status_result\")\n",
        "        quotedTweetInfo = quoted_info['result'] if (quoted_info and 'result' in quoted_info) else None\n",
        "\n",
        "        quoted_tweet_id = None\n",
        "        quoted_tweet_user_id = None\n",
        "        quoted_tweet_user_name = None\n",
        "        if (quotedTweetInfo and quotedTweetInfo[\"__typename\"] == 'Tweet'):\n",
        "            quoted_tweet_id = quotedTweetInfo[\"rest_id\"]\n",
        "            quoted_tweet_user_id = quotedTweetInfo[\"core\"][\"user_results\"][\"result\"][\"rest_id\"]\n",
        "            quoted_tweet_user_name = quotedTweetInfo[\"core\"][\"user_results\"][\"result\"][\"legacy\"][\"screen_name\"]\n",
        "\n",
        "        #Mentioned user\n",
        "        mentioned_list = item[\"data\"][\"legacy\"][\"entities\"][\"user_mentions\"]\n",
        "\n",
        "        cleaned.append({\n",
        "            \"tweet_id\":tweet_id,\n",
        "            \"views_count\":views_count,\n",
        "            \"favorite_count\":favorite_count,\n",
        "            \"retweet_count\":retweet_count,\n",
        "            \"full_text\":full_text,\n",
        "            \"created_at\":created_at,\n",
        "            \"hashtags\":hashtags,\n",
        "            \"user_id\":user_id,\n",
        "            \"user_followers_count\":user_followers_count,\n",
        "            \"user_location\":user_location,\n",
        "            \"user_screen_name\":user_screen_name,\n",
        "            \"conversation_id\":conversation_id,\n",
        "            \"quoted_tweet_id\":quoted_tweet_id,\n",
        "            \"quoted_tweet_user_id\":quoted_tweet_user_id,\n",
        "            \"quoted_tweet_user_name\":quoted_tweet_user_name,\n",
        "            \"mentioned_list\":mentioned_list,\n",
        "        })\n",
        "    return cleaned\n",
        "\n",
        "cleaned_data = clean_data(merged_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c48307fd",
      "metadata": {
        "id": "c48307fd"
      },
      "outputs": [],
      "source": [
        "# Output to csv format\n",
        "import csv\n",
        "\n",
        "# Change name to 2021 or 2023\n",
        "output_csv_path = \"./data_202X.csv\"\n",
        "\n",
        "# Extract headers\n",
        "headers = cleaned_data[0].keys() if cleaned_data else []\n",
        "\n",
        "with open(output_csv_path, \"w\", newline=\"\") as output_csv_file:\n",
        "    # Create a CSV writer object\n",
        "    csv_writer = csv.DictWriter(output_csv_file, fieldnames=headers)\n",
        "\n",
        "    # Write the header row\n",
        "    csv_writer.writeheader()\n",
        "\n",
        "    # Write the data rows\n",
        "    for item in cleaned_data:\n",
        "        csv_writer.writerow(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a184b88",
      "metadata": {
        "id": "0a184b88"
      },
      "outputs": [],
      "source": [
        "### Co-hashtag Network\n",
        "\n",
        "from itertools import combinations\n",
        "\n",
        "# Change name to 2021 or 2023\n",
        "output_node='./cohash_nodes_202X.csv'\n",
        "output_edge='./cohash_edge_202X.csv'\n",
        "\n",
        "headers_node=['Id', 'Label']\n",
        "headers_edge=['Source', 'Target']\n",
        "\n",
        "nodes = set()\n",
        "edges = []\n",
        "\n",
        "for item in cleaned_data:\n",
        "    hashtags = item[\"hashtags\"]\n",
        "    if hashtags and len(hashtags) > 0:\n",
        "        # add nodes\n",
        "        for hashtag in hashtags:\n",
        "            if hashtag not in nodes:\n",
        "                nodes.add(hashtag)\n",
        "        # add edges\n",
        "        for tag1, tag2 in combinations(hashtags, 2):\n",
        "            edges.append({\"Source\": tag1, \"Target\": tag2})\n",
        "\n",
        "with open(output_node, 'w', newline='') as output_node_file:\n",
        "    csv_writer = csv.DictWriter(output_node_file, fieldnames=headers_node)\n",
        "    csv_writer.writeheader()\n",
        "    for node in nodes:\n",
        "        output={\n",
        "            \"Id\": node,\n",
        "            \"Label\":f\"#{node}\",\n",
        "        }\n",
        "        csv_writer.writerow(output)\n",
        "\n",
        "with open(output_edge, 'w', newline='') as output_edge_file:\n",
        "    csv_writer = csv.DictWriter(output_edge_file, fieldnames=headers_edge)\n",
        "    csv_writer.writeheader()\n",
        "    for edge in edges:\n",
        "        csv_writer.writerow(edge)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43ed7ce3",
      "metadata": {
        "id": "43ed7ce3"
      },
      "outputs": [],
      "source": [
        "### User Interaction Network\n",
        "\n",
        "# Change name to 2021 or 2023\n",
        "output_node='./Gephi_nodes_202X.csv'\n",
        "output_edge='./Gephi_edge_202X.csv'\n",
        "\n",
        "headers_node=['Id', 'Label']\n",
        "headers_edge=['Source', 'Target', 'Relation']\n",
        "\n",
        "with open(output_node, 'w', newline='') as output_node_file:\n",
        "    csv_writer = csv.DictWriter(output_node_file, fieldnames=headers_node)\n",
        "    csv_writer.writeheader()\n",
        "    for item in cleaned_data:\n",
        "        output={\n",
        "            \"Id\":item[\"user_id\"],\n",
        "            \"Label\":item[\"user_screen_name\"],\n",
        "        }\n",
        "        csv_writer.writerow(output)\n",
        "\n",
        "\n",
        "edge_data = []\n",
        "for item in cleaned_data:\n",
        "    user_id = item[\"user_id\"]\n",
        "    quoted_tweet_user_id = item[\"quoted_tweet_user_id\"]\n",
        "    mentioned_list=item[\"mentioned_list\"]\n",
        "    if quoted_tweet_user_id:\n",
        "        edge_data.append({\n",
        "            \"Source\":quoted_tweet_user_id,\n",
        "            \"Target\":user_id,\n",
        "            \"Relation\":\"Quoted by\",\n",
        "        })\n",
        "    if len(mentioned_list) > 0:\n",
        "        for mentioned in mentioned_list:\n",
        "            edge_data.append({\n",
        "                \"Source\":mentioned[\"id_str\"],\n",
        "                \"Target\":user_id,\n",
        "                \"Relation\":\"Mentioned by\",\n",
        "            })\n",
        "\n",
        "\n",
        "with open(output_edge, 'w', newline='') as output_edge_file:\n",
        "    csv_writer = csv.DictWriter(output_edge_file, fieldnames=headers_edge)\n",
        "    csv_writer.writeheader()\n",
        "    for item in edge_data:\n",
        "        csv_writer.writerow(item)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3a36934",
      "metadata": {
        "id": "c3a36934"
      },
      "outputs": [],
      "source": [
        "### See if some of the influential 2023 users were in 2021 user interaction\n",
        "\n",
        "red_users_to_highlight = ['rec777777', 'LordOfFreedom2','MikeTho0495078'\n",
        "                          ,'PaulssonChris','lanEnglishman','NorthBritannia']\n",
        "blue_users_to_highlight = ['ScienceBlog3', 'Prof_Dr_SG', 'Fossil_Herb'\n",
        "                           , 'Royalacresrod', 'Sasha67Oz', 'peblackstock']\n",
        "\n",
        "active_in_2021 = set()\n",
        "\n",
        "for item in cleaned_data:\n",
        "    label = item[\"user_screen_name\"]\n",
        "    if (label in red_users_to_highlight) or (label in blue_users_to_highlight):\n",
        "        activeIn2021.add(label)\n",
        "\n",
        "print(active_in_2021) # It is a empty set"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}